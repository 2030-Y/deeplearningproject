{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"},{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":1193409,"sourceType":"datasetVersion","datasetId":679322},{"sourceId":14041607,"sourceType":"datasetVersion","datasetId":8939410},{"sourceId":14041695,"sourceType":"datasetVersion","datasetId":8939450}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\nfrom sklearn.model_selection import train_test_split\n\nimport albumentations as A\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\nfrom tensorflow.keras import layers\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\nfrom tensorflow.keras import backend as K\n\nfrom tensorflow.keras import mixed_precision\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.731265Z","iopub.execute_input":"2025-12-07T10:01:54.732000Z","iopub.status.idle":"2025-12-07T10:01:54.737180Z","shell.execute_reply.started":"2025-12-07T10:01:54.731974Z","shell.execute_reply":"2025-12-07T10:01:54.736573Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Append the absolute file path to the CSV files to fetch the training and testing data.\ndef append_path(df, path):\n    # Append .jpg extenstion\n    def append_ext(fn):\n        return fn + \".jpg\"\n\n    df['image'] = df['image'].apply(append_ext)\n    print(\"Dataframe Head:\\n\", df['image'].head())\n\n    # Append absolute file path to where the images are located. \n    abs_file_names = []\n    for file_name in df['image']:\n        tmp = path + '/' + file_name\n        abs_file_names.append(tmp)\n\n    df['image'] = abs_file_names\n    print(\"Updated DF with Extenstion and Path:\\n\", df['image'][0])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.738299Z","iopub.execute_input":"2025-12-07T10:01:54.738511Z","iopub.status.idle":"2025-12-07T10:01:54.754256Z","shell.execute_reply.started":"2025-12-07T10:01:54.738496Z","shell.execute_reply":"2025-12-07T10:01:54.753696Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def cosine_decay_with_warmup(global_step,\n                                learning_rate_base,\n                                total_steps,\n                                warmup_learning_rate=0.0,\n                                warmup_steps=0,\n                                hold_base_rate_steps=0):\n\n    global_step = tf.cast(global_step, tf.float32)\n    total_steps = tf.cast(total_steps, tf.float32)\n    warmup_steps = tf.cast(warmup_steps, tf.float32)\n    hold_base_rate_steps = tf.cast(hold_base_rate_steps, tf.float32)\n\n    # Linear warmup\n    slope = (learning_rate_base - warmup_learning_rate) / tf.maximum(warmup_steps, 1.0)\n    warmup_rate = slope * global_step + warmup_learning_rate\n\n    # Cosine decay\n    cosine_steps = total_steps - warmup_steps - hold_base_rate_steps\n    cosine_steps = tf.maximum(cosine_steps, 1.0)\n\n    cosine_global_step = tf.minimum(global_step - warmup_steps - hold_base_rate_steps,\n                                    cosine_steps)\n\n    cosine_decay = 0.5 * learning_rate_base * (\n        1 + tf.cos(np.pi * cosine_global_step / cosine_steps)\n    )\n\n    # Conditions\n    lr = tf.where(global_step < warmup_steps, warmup_rate, cosine_decay)\n    lr = tf.where(global_step > total_steps, 0.0, lr)\n\n    return lr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.755056Z","iopub.execute_input":"2025-12-07T10:01:54.755703Z","iopub.status.idle":"2025-12-07T10:01:54.771494Z","shell.execute_reply.started":"2025-12-07T10:01:54.755685Z","shell.execute_reply":"2025-12-07T10:01:54.770918Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class WarmUpCosineDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self,\n                 learning_rate_base,\n                 total_steps,\n                 warmup_learning_rate=0.0,\n                 warmup_steps=0,\n                 hold_base_rate_steps=0,\n                 name=None):\n        super().__init__()\n        self.learning_rate_base = learning_rate_base\n        self.total_steps = total_steps\n        self.warmup_learning_rate = warmup_learning_rate\n        self.warmup_steps = warmup_steps\n        self.hold_base_rate_steps = hold_base_rate_steps\n        self.name = name\n\n    def __call__(self, step):\n        return cosine_decay_with_warmup(\n            global_step=step,\n            learning_rate_base=self.learning_rate_base,\n            total_steps=self.total_steps,\n            warmup_learning_rate=self.warmup_learning_rate,\n            warmup_steps=self.warmup_steps,\n            hold_base_rate_steps=self.hold_base_rate_steps\n        )\n\n    def get_config(self):\n        return {\n            \"learning_rate_base\": self.learning_rate_base,\n            \"total_steps\": self.total_steps,\n            \"warmup_learning_rate\": self.warmup_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"hold_base_rate_steps\": self.hold_base_rate_steps,\n            \"name\": self.name,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.772638Z","iopub.execute_input":"2025-12-07T10:01:54.772838Z","iopub.status.idle":"2025-12-07T10:01:54.785879Z","shell.execute_reply.started":"2025-12-07T10:01:54.772821Z","shell.execute_reply":"2025-12-07T10:01:54.785122Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def save_plot(history, save_dir):\n\n    # Accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(save_dir + '_accuracy.jpg')\n    plt.close()\n\n    # Loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(save_dir + '_loss.jpg')\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.786618Z","iopub.execute_input":"2025-12-07T10:01:54.786899Z","iopub.status.idle":"2025-12-07T10:01:54.804787Z","shell.execute_reply.started":"2025-12-07T10:01:54.786875Z","shell.execute_reply":"2025-12-07T10:01:54.804180Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def model_parameter(selected_model):\n    model_list = {\n        \"model1\": {\n            \"backbone\": EfficientNetB4,\n            \"target\": 9,\n            \"resize\": 380,\n            \"metadata\": False,\n            \"initial_lr\": 3e-5,\n            \"epochs\": 15,\n            'train_batch_size': 8,\n            'validation_batch_size': 8,\n            \"savedModelByName\": \"Model1_EffB4.keras\",\n            \"saveFinalModelBy\": \"Model1_EffB4\",\n            'log_by': \"Model1_EffB4.csv\",\n            'save_plot_name': 'Model1_EffB4',\n            'prediction_csv_name': 'Model1_EffB4_prediction',\n            'print_hyper_parameter': True,\n            'input_image_size': 768,\n            'print_trainable_layers': True, \n            'print_model_summary': False,\n            'visualise_augmented_data': False\n        },\n        \"model2\": {\n            \"backbone\": EfficientNetB6,\n            \"target\": 9,\n            \"resize\": 528,\n            \"metadata\": False,\n            \"initial_lr\": 3e-5,\n            \"epochs\": 15,\n            'input_image_size': 768,\n            'train_batch_size': 8,\n            'validation_batch_size': 8,\n            \"savedModelByName\": \"Model2_EffB6.h5\",\n            \"saveFinalModelBy\": \"Model2_EffB6\",\n            'log_by': \"Model2_EffB6.csv\",\n            'save_plot_name': 'Model2_EffB6',\n            'prediction_csv_name': 'Model2_EffB6prediction',\n            'print_hyper_parameter': True,\n            'print_trainable_layers': False,\n            'print_model_summary': False,\n            'visualise_augmented_data': False\n        },\n        \"model3\": {\n            \"backbone\": EfficientNetB7,\n            \"target\": 9,\n            \"resize\": 380,\n            \"metadata\": False,\n            \"initial_lr\": 1e-5,\n            \"epochs\": 15,\n            'input_image_size': 768,\n            'train_batch_size': 4,\n            'validation_batch_size': 4,\n            \"savedModelByName\": \"Model3_EffB7.h5\",\n            \"saveFinalModelBy\": \"Model3\",\n            'log_by': \"Model3_EffB7.csv\",\n            'save_plot_name': 'Model3_EffB7',\n            'prediction_csv_name': 'Model3_EffB7prediction',\n            'print_hyper_parameter': True,\n            'print_trainable_layers': False,\n            'print_model_summary': False,\n            'visualise_augmented_data': False\n        }\n    }\n    return model_list[selected_model]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.831493Z","iopub.execute_input":"2025-12-07T10:01:54.832044Z","iopub.status.idle":"2025-12-07T10:01:54.838263Z","shell.execute_reply.started":"2025-12-07T10:01:54.832024Z","shell.execute_reply":"2025-12-07T10:01:54.837507Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Initialise the EfficientNet Model for transfer learning\ndef EffNet(input_size, num_classess, pretrained_model, lr_rate,\n           print_trainable_layers=False, print_model_summary=False):\n    # Get the EfficientNet Model\n    base_model = pretrained_model(\n        weights='imagenet',\n        input_shape=input_size,\n        include_top=False\n    )\n\n    # Keep the BatchNorm layer freeze, and unfreeze all other layers\n    def unfreeze_model(model, print_trainable, print_summary):\n        # unfreeze the layers while leaving BatchNorm layers frozen\n        for layer in model.layers[:]:\n            if isinstance(layer, layers.BatchNormalization):\n                layer.trainable = False\n                \n        # Print trainable layer summary\n        if print_trainable:\n            for layer in model.layers:\n                print(layer, layer.trainable)\n\n        # Print Model summary\n        if print_summary:\n            model.summary()\n\n    # Unfreeze the model\n    unfreeze_model(base_model, print_trainable_layers, print_model_summary)\n\n    # Add dense and output layer\n    model = keras.Sequential()\n    model.add(base_model)\n    model.add(layers.Flatten(name='top_flatten'))\n    model.add(layers.Dense(500, activation='relu', name='dense_500'))\n    model.add(layers.Dense(256, activation='relu', name='dense_256'))\n    model.add(layers.Dense(num_classess, activation='softmax', name='output_layer'))\n\n    # Initialise the optimizer and compile the model\n    lr_schedule = WarmUpCosineDecaySchedule(\n    learning_rate_base=hyper_param['learning_rate_base'],\n    total_steps=total_steps,\n    warmup_learning_rate=hyper_param['warmup_learning_rate'],\n    warmup_steps=warmup_steps,\n    hold_base_rate_steps=0,\n    )\n\n    optimizer = Adam(learning_rate=lr_schedule)\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n\n    # print the FC layer summary\n    if print_model_summary:\n        model.summary()\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.839378Z","iopub.execute_input":"2025-12-07T10:01:54.839551Z","iopub.status.idle":"2025-12-07T10:01:54.858416Z","shell.execute_reply.started":"2025-12-07T10:01:54.839538Z","shell.execute_reply":"2025-12-07T10:01:54.857822Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Fit the model on training and validation dataset and star the training process.\ndef train_model(model, train_dataset, epoch,\n                validation_dataset, callback):\n\n    return model.fit(\n        train_dataset,\n        epochs=epoch,\n        validation_data=validation_dataset,\n        verbose=1,\n        callbacks=callback\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.859024Z","iopub.execute_input":"2025-12-07T10:01:54.859296Z","iopub.status.idle":"2025-12-07T10:01:54.875093Z","shell.execute_reply.started":"2025-12-07T10:01:54.859278Z","shell.execute_reply":"2025-12-07T10:01:54.874369Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# Augment the dataset\nIMAGENET_MEAN = tf.constant([0.485, 0.456, 0.406], dtype=tf.float32)\nIMAGENET_STD  = tf.constant([0.229, 0.224, 0.225], dtype=tf.float32)\ndef augment(image, image_size, training=True):\n\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n\n    if training:\n\n        rand_scale = tf.random.uniform([], 0.8, 1.0)\n        orig_h = tf.shape(image)[0]\n        orig_w = tf.shape(image)[1]\n        crop_h = tf.cast(rand_scale * tf.cast(orig_h, tf.float32), tf.int32)\n        crop_w = tf.cast(rand_scale * tf.cast(orig_w, tf.float32), tf.int32)\n    \n        image = tf.image.random_crop(image, size=[crop_h, crop_w, 3])\n        image = tf.image.resize(image, [image_size, image_size])\n    \n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n    \n        k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n        image = tf.image.rot90(image, k=k)\n    \n        image = tf.image.random_brightness(image, max_delta=0.2)\n        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n        image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n        image = tf.image.random_hue(image, max_delta=0.02)\n    \n        image = tf.clip_by_value(image, 0.0, 1.0)\n    \n        noise_std = tf.random.uniform([], 0.0, 0.05)  \n        noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=noise_std)\n        image = image + noise\n        image = tf.clip_by_value(image, 0.0, 1.0)\n\n        def apply_cutout(img):\n            h = tf.shape(img)[0]\n            w = tf.shape(img)[1]\n        \n      \n            cutout_frac = tf.random.uniform([], 0.2, 0.4)\n            ch = tf.cast(cutout_frac * tf.cast(h, tf.float32), tf.int32)\n            cw = tf.cast(cutout_frac * tf.cast(w, tf.float32), tf.int32)\n        \n    \n            cy = tf.random.uniform([], 0, h - ch + 1, dtype=tf.int32)\n            cx = tf.random.uniform([], 0, w - cw + 1, dtype=tf.int32)\n        \n    \n            mask = tf.ones((h, w), dtype=tf.float32)\n            mask = tf.tensor_scatter_nd_update(\n                mask,\n                indices=tf.reshape(\n                    tf.stack(tf.meshgrid(tf.range(cy, cy + ch),\n                                         tf.range(cx, cx + cw),\n                                         indexing=\"ij\"), axis=-1),\n                    [-1, 2]\n                ),\n                updates=tf.zeros([ch * cw], dtype=tf.float32)\n            )\n        \n    \n            mask = tf.expand_dims(mask, -1)\n            mask = tf.concat([mask, mask, mask], axis=-1)\n        \n            return img * mask\n    \n        do_cutout = tf.less(tf.random.uniform([]), 0.5)\n        image = tf.cond(do_cutout, lambda: apply_cutout(image), lambda: image)\n\n    else:\n        image = tf.image.resize(image, [image_size, image_size])\n    \n    image = (image - IMAGENET_MEAN) / IMAGENET_STD\n    \n    return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.875895Z","iopub.execute_input":"2025-12-07T10:01:54.876528Z","iopub.status.idle":"2025-12-07T10:01:54.895475Z","shell.execute_reply.started":"2025-12-07T10:01:54.876504Z","shell.execute_reply":"2025-12-07T10:01:54.894932Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef build_tf_dataset(\n    df,\n    image_size,\n    batch_size,\n    num_classes,\n    label_col=\"diagnosis_idx\",\n    shuffle=False,\n    repeat=False,\n    training=True,\n):\n    paths = df[\"image\"].values\n    labels = df[label_col].values.astype(\"int32\")\n\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n\n    if shuffle:\n        ds = ds.shuffle(len(df), reshuffle_each_iteration=True)\n\n    def _load_image(path, label):\n        image_bytes = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image_bytes, channels=3)\n        image = augment(image, image_size, training=training)\n        label_onehot = tf.one_hot(label, num_classes)\n        return image, label_onehot\n\n    ds = ds.map(_load_image, num_parallel_calls=AUTOTUNE)\n\n    if repeat:\n        ds = ds.repeat()\n\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.897159Z","iopub.execute_input":"2025-12-07T10:01:54.897418Z","iopub.status.idle":"2025-12-07T10:01:54.911423Z","shell.execute_reply.started":"2025-12-07T10:01:54.897398Z","shell.execute_reply":"2025-12-07T10:01:54.910755Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def build_tf_val_dataset(\n    df,\n    image_size,\n    batch_size,\n    num_classes,\n    transforms_val,\n    label_col=\"diagnosis_idx\",\n):\n\n    return build_tf_dataset(\n        df=df,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_classes=num_classes,\n        transforms=transforms_val,\n        label_col=label_col,\n        shuffle=False,\n        repeat=False,\n    )\n\ndef build_tf_test_dataset(df, image_size, batch_size):\n    paths = df[\"image\"].values\n    ds = tf.data.Dataset.from_tensor_slices(paths)\n\n    def _load_image(path):\n        image_bytes = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image_bytes, channels=3)\n        image = augment(image, image_size, training=False)  \n        return image\n\n    ds = ds.map(_load_image, num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.912019Z","iopub.execute_input":"2025-12-07T10:01:54.912211Z","iopub.status.idle":"2025-12-07T10:01:54.928628Z","shell.execute_reply.started":"2025-12-07T10:01:54.912197Z","shell.execute_reply":"2025-12-07T10:01:54.928053Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class DepthwiseConv2DCompat(keras.layers.DepthwiseConv2D):\n    def __init__(self, *args, groups=None, **kwargs):\n        super().__init__(*args, **kwargs)\n\n\nclass Cast(keras.layers.Layer):\n    def __init__(self, dtype=None, **kwargs):\n        super().__init__(**kwargs)\n        self._target_dtype = tf.as_dtype(dtype) if dtype is not None else None\n\n    def call(self, inputs):\n        if self._target_dtype is None:\n            return tf.cast(inputs, tf.float32)\n        return tf.cast(inputs, self._target_dtype)\n\nlegacy_custom_objects = {\n    \"DepthwiseConv2D\": DepthwiseConv2DCompat,\n    \"Cast\": Cast,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.929389Z","iopub.execute_input":"2025-12-07T10:01:54.929682Z","iopub.status.idle":"2025-12-07T10:01:54.944639Z","shell.execute_reply.started":"2025-12-07T10:01:54.929661Z","shell.execute_reply":"2025-12-07T10:01:54.943919Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Data path\n    TRAIN_CSV = \"/kaggle/input/processedcsvs/Processed CSV's/train_2020_and_2019_with_9_Labels.csv\"\n    TEST_CSV  = \"/kaggle/input/processedcsvs/Processed CSV's/test_2020_no_PateintDetail.csv\"\n    TRAIN_IMG_DIR_1 = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/train\"\n    TRAIN_IMG_DIR_2 = \"/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n    TEST_IMG_DIR = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/test\"\n\n    #  Select model to train\n    model_config = \"model1\"  \n    selected_model = model_parameter(model_config)\n\n    # Define log, plot, model, prediction files\n    log_path = \"./runs/\"\n    os.makedirs(log_path, exist_ok=True)\n\n    plot_path = \"./plot/\"\n    os.makedirs(plot_path, exist_ok=True)\n\n    save_model_path = \"./saveModel/\"\n    os.makedirs(save_model_path, exist_ok=True)\n\n    prediction_path = \"./prediction/\"\n    os.makedirs(prediction_path, exist_ok=True)\n\n    # join CSV & image path\n    label = pd.read_csv(TRAIN_CSV)\n    class_names = sorted(label[\"diagnosis\"].unique())\n    label2idx = {c: i for i, c in enumerate(class_names)}\n    idx2label = {i: c for c, i in label2idx.items()}\n\n    label[\"diagnosis_idx\"] = label[\"diagnosis\"].map(label2idx)\n    num_classes = len(class_names)\n    test_csv = pd.read_csv(TEST_CSV)\n\n    def attach_train_paths(df):\n        df = df.copy()\n        df[\"image\"] = df[\"image\"].astype(str) + \".jpg\"\n\n        full_paths = []\n        miss_cnt = 0\n\n        for img in df[\"image\"]:\n            p1 = os.path.join(TRAIN_IMG_DIR_1, img)  # 2020\n            p2 = os.path.join(TRAIN_IMG_DIR_2, img)  # 2019\n\n            if os.path.exists(p1):\n                full_paths.append(p1)\n            elif os.path.exists(p2):\n                full_paths.append(p2)\n            else:\n                full_paths.append(p1)\n                miss_cnt += 1\n\n        if miss_cnt > 0:\n            print(f\"[WARNING] {miss_cnt} images not found in either train dir, \"\n                  f\"using 2020 path by default. Check names or dirs.\")\n            \n        df[\"image\"] = full_paths\n        return df\n\n    label = attach_train_paths(label)\n\n    def attach_test_paths(df):\n        df = df.copy()\n        df[\"image\"] = df[\"image\"].astype(str) + \".jpg\"\n        df[\"image\"] = df[\"image\"].apply(\n            lambda x: os.path.join(TEST_IMG_DIR, x)\n        )\n        return df\n    test_csv = attach_test_paths(test_csv)\n\n    # Hyper Parameter\n    hyper_param = {\n        'seed': 42,\n        'image_size': selected_model['resize'],\n        'backbone_model': selected_model['backbone'],\n        'early_stop': 10,\n        'num_class': selected_model['target'],\n        'train_batch_size': selected_model['train_batch_size'],\n        'test_batch_size': 1,\n        'validation_batch_size': selected_model['validation_batch_size'],\n        'epoch': selected_model['epochs'],\n        'warmup_epoch': 1,\n        'learning_rate_base': selected_model['initial_lr'],\n        'warmup_learning_rate': selected_model['initial_lr'],\n        'training_sample_count': label.shape[0],\n        'save_model': selected_model['savedModelByName'],\n        'save_final_model': selected_model['saveFinalModelBy']\n    }\n\n    image_resize = (hyper_param['image_size'], hyper_param['image_size'])\n    image_shape = image_resize + (3,)\n\n    # Total training steps in Warmup\n    total_steps = int(hyper_param['epoch'] *\n                      hyper_param['training_sample_count'] /\n                      hyper_param['train_batch_size'])\n    # Compute the number of warmup batches.\n    warmup_steps = int(hyper_param['warmup_epoch'] *\n                       hyper_param['training_sample_count'] /\n                       hyper_param['train_batch_size'])\n\n    # Print Hyper parameter\n    if selected_model['print_hyper_parameter']:\n        print(\"\\n####################### Hyper Parameter #################################\\n\")\n        pprint.pprint(hyper_param)\n        print('\\nImage Shape: {}'.format(image_shape))\n        print('Total training steps in Warmup: {}'.format(total_steps))\n        print('Number of Warmup Batch: {}\\n'.format(warmup_steps))\n        print(\"\\nTrain Label shape: \", label.shape)\n        print(\"Test Label shape: \", test_csv.shape)\n\n\n    #Initialise Pre-train Model\n    # model = EffNet(\n    #     input_size=image_shape,\n    #     num_classess=hyper_param['num_class'],\n    #     pretrained_model=hyper_param['backbone_model'],\n    #     lr_rate=hyper_param['learning_rate_base'],\n    #     print_trainable_layers=selected_model['print_trainable_layers'],\n    #     print_model_summary=selected_model['print_model_summary']\n    # )\n    model = tf.keras.models.load_model(\"/kaggle/input/saved1/saveModel/Model1_EffB4.hdf5\",custom_objects=legacy_custom_objects,compile=False)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=hyper_param['learning_rate_base'])\n    model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\n    # Preprocess and Augment Image for train, test and validation set. \n    image_size = hyper_param['image_size']\n    train_bs = hyper_param['train_batch_size']\n    val_bs = hyper_param['validation_batch_size']\n    train_df, val_df = train_test_split(label,test_size=0.2,random_state=hyper_param['seed'],stratify=label['diagnosis'])\n\n\n    # Prepare train, validation Generator\n    train_ds = build_tf_dataset(\n        df=train_df,\n        image_size=image_size,\n        batch_size=train_bs,\n        num_classes=hyper_param['num_class'],\n        label_col=\"diagnosis_idx\",\n        shuffle=True,\n        repeat=False,\n        training=True,      \n    )\n    \n    val_ds = build_tf_dataset(\n        df=val_df,\n        image_size=image_size,\n        batch_size=val_bs,\n        num_classes=hyper_param['num_class'],\n        label_col=\"diagnosis_idx\",\n        shuffle=False,\n        repeat=False,\n        training=False,    \n    )\n    # Define Early Stopping on validation loss\n    es = EarlyStopping(\n        monitor='val_loss',\n        mode='min',\n        patience=hyper_param['early_stop'],\n        verbose=1,\n        restore_best_weights=True\n    )\n\n    # Save model after each epoch\n    ck = ModelCheckpoint(\n        # filepath=os.path.join(save_model_path, hyper_param['save_model']),\n        filepath=os.path.join(save_model_path, hyper_param['save_model'].replace(\".h5\", \".keras\")),\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=False,\n        save_weights_only=False,\n        # mode='auto'\n    )\n\n    # Save logs to CSV\n    logs = CSVLogger(\n        os.path.join(log_path, selected_model['log_by']),\n        separator=\",\",\n        append=False\n    )\n\n    # Callback list\n    call_backs = [ck, logs, es]\n\n    already_trained= 14\n\n    # Start the training process\n    print('\\n\\n---------------- Staring the Training Process... --------------- ')\n    history = model.fit(\n        train_ds,\n        epochs=hyper_param['epoch'],\n        initial_epoch=already_trained,\n        validation_data=val_ds,\n        callbacks=call_backs,\n        verbose=1\n    )\n    print(\"\\n ----------------- Model is trained --------------------------\")\n\n    # Training and validation: accuracy & loss\n    print(\"\\n------ Saving Training and Validation Plot --------\")\n    # save_plot(history=history,\n    #           save_dir=os.path.join(plot_path, selected_model['save_plot_name']))\n\n    # Predict on Testing Set\n    test_ds = build_tf_test_dataset(\n        df=test_csv,\n        image_size=image_size,\n        batch_size=hyper_param['test_batch_size'],\n        # num_classes=hyper_param['num_class'], \n        # label_col=\"diagnosis_idx\",             \n    )\n\n    print(\"\\n------ Predicting on Testset --------\")\n    pred = model.predict(test_ds, verbose=1)\n    predicted_class_indices = np.argmax(pred, axis=1)\n\n    # Map the predicted labels with their unique ids\n    predictions = [idx2label[i] for i in predicted_class_indices]\n\n    results = pd.DataFrame({\n        \"Filename\": test_csv[\"image\"],   \n        \"Predictions\": predictions\n    })\n\n    results.to_csv(\n        os.path.join(prediction_path, selected_model['prediction_csv_name'] + \".csv\"),\n        index=False\n    )\n\n    # Save Trained Model\n    print(\"\\n ------------ Saving the Trained model ------------------------------------\")\n    final_model_dir = os.path.join(save_model_path, hyper_param['save_final_model'])\n    os.makedirs(final_model_dir, exist_ok=True)\n\n    model.save(final_model_dir + \".keras\", include_optimizer=True)\n\n    print(\"\\n---------------------- Completed Model Training & Prediction ---------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-07T10:01:54.945307Z","iopub.execute_input":"2025-12-07T10:01:54.945883Z","iopub.status.idle":"2025-12-07T11:26:57.709386Z","shell.execute_reply.started":"2025-12-07T10:01:54.945866Z","shell.execute_reply":"2025-12-07T11:26:57.708694Z"}},"outputs":[{"name":"stdout","text":"\n####################### Hyper Parameter #################################\n\n{'backbone_model': <function EfficientNetB4 at 0x782da0520400>,\n 'early_stop': 10,\n 'epoch': 15,\n 'image_size': 380,\n 'learning_rate_base': 3e-05,\n 'num_class': 9,\n 'save_final_model': 'Model1_EffB4',\n 'save_model': 'Model1_EffB4.keras',\n 'seed': 42,\n 'test_batch_size': 1,\n 'train_batch_size': 8,\n 'training_sample_count': 58031,\n 'validation_batch_size': 8,\n 'warmup_epoch': 1,\n 'warmup_learning_rate': 3e-05}\n\nImage Shape: (380, 380, 3)\nTotal training steps in Warmup: 108808\nNumber of Warmup Batch: 7253\n\n\nTrain Label shape:  (58031, 3)\nTest Label shape:  (10875, 1)\n\n\n---------------- Staring the Training Process... --------------- \nEpoch 15/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1765101793.191506     103 service.cc:148] XLA service 0x782d48002d40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1765101793.193230     103 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1765101803.063177     103 cuda_dnn.cc:529] Loaded cuDNN version 90300\nE0000 00:00:1765101814.614392     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1765101814.799318     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1765101815.202880     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1765101815.403747     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1765101815.975278     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1765101816.203461     103 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nI0000 00:00:1765101851.841702     103 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m5803/5803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617ms/step - accuracy: 0.7230 - loss: 0.7597\nEpoch 15: saving model to ./saveModel/Model1_EffB4.keras\n\u001b[1m5803/5803\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4275s\u001b[0m 719ms/step - accuracy: 0.7230 - loss: 0.7597 - val_accuracy: 0.8306 - val_loss: 0.4886\nRestoring model weights from the end of the best epoch: 15.\n\n ----------------- Model is trained --------------------------\n\n------ Saving Training and Validation Plot --------\n\n------ Predicting on Testset --------\n\u001b[1m10875/10875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 70ms/step\n\n ------------ Saving the Trained model ------------------------------------\n\n---------------------- Completed Model Training & Prediction ---------------------------\n","output_type":"stream"}],"execution_count":26}]}