{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":20270,"databundleVersionId":1222630,"sourceType":"competition"},{"sourceId":1193409,"sourceType":"datasetVersion","datasetId":679322},{"sourceId":14062732,"sourceType":"datasetVersion","datasetId":8950881},{"sourceId":676747,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":513139,"modelId":527773}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\nimport pprint\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\n\nimport keras\n\nfrom keras import layers, callbacks, optimizers, mixed_precision\nfrom keras.applications import EfficientNetB5\n\nmixed_precision.set_global_policy('mixed_float16')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.626834Z","iopub.execute_input":"2025-12-08T15:48:05.627470Z","iopub.status.idle":"2025-12-08T15:48:05.632152Z","shell.execute_reply.started":"2025-12-08T15:48:05.627442Z","shell.execute_reply":"2025-12-08T15:48:05.631330Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Append the absolute file path to the CSV files to fetch the training and testing data.\ndef append_path(df, path):\n    # Append .jpg extenstion\n    def append_ext(fn):\n        return fn + \".jpg\"\n\n    df['image'] = df['image'].apply(append_ext)\n    print(\"Dataframe Head:\\n\", df['image'].head())\n\n    # Append absolute file path to where the images are located. \n    abs_file_names = []\n    for file_name in df['image']:\n        tmp = path + '/' + file_name\n        abs_file_names.append(tmp)\n\n    df['image'] = abs_file_names\n    print(\"Updated DF with Extenstion and Path:\\n\", df['image'][0])\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.633073Z","iopub.execute_input":"2025-12-08T15:48:05.633328Z","iopub.status.idle":"2025-12-08T15:48:05.651875Z","shell.execute_reply.started":"2025-12-08T15:48:05.633303Z","shell.execute_reply":"2025-12-08T15:48:05.651273Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def cosine_decay_with_warmup(global_step,\n                                learning_rate_base,\n                                total_steps,\n                                warmup_learning_rate=0.0,\n                                warmup_steps=0,\n                                hold_base_rate_steps=0):\n\n    global_step = tf.cast(global_step, tf.float32)\n    total_steps = tf.cast(total_steps, tf.float32)\n    warmup_steps = tf.cast(warmup_steps, tf.float32)\n    hold_base_rate_steps = tf.cast(hold_base_rate_steps, tf.float32)\n\n    # Linear warmup\n    slope = (learning_rate_base - warmup_learning_rate) / tf.maximum(warmup_steps, 1.0)\n    warmup_rate = slope * global_step + warmup_learning_rate\n\n    # Cosine decay\n    cosine_steps = total_steps - warmup_steps - hold_base_rate_steps\n    cosine_steps = tf.maximum(cosine_steps, 1.0)\n\n    cosine_global_step = tf.minimum(global_step - warmup_steps - hold_base_rate_steps,\n                                    cosine_steps)\n\n    cosine_decay = 0.5 * learning_rate_base * (\n        1 + tf.cos(np.pi * cosine_global_step / cosine_steps)\n    )\n\n    # Conditions\n    lr = tf.where(global_step < warmup_steps, warmup_rate, cosine_decay)\n    lr = tf.where(global_step > total_steps, 0.0, lr)\n\n    return lr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.652607Z","iopub.execute_input":"2025-12-08T15:48:05.652853Z","iopub.status.idle":"2025-12-08T15:48:05.666391Z","shell.execute_reply.started":"2025-12-08T15:48:05.652831Z","shell.execute_reply":"2025-12-08T15:48:05.665608Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class WarmUpCosineDecaySchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self,\n                 learning_rate_base,\n                 total_steps,\n                 warmup_learning_rate=0.0,\n                 warmup_steps=0,\n                 hold_base_rate_steps=0,\n                 name=None):\n        super().__init__()\n        self.learning_rate_base = learning_rate_base\n        self.total_steps = total_steps\n        self.warmup_learning_rate = warmup_learning_rate\n        self.warmup_steps = warmup_steps\n        self.hold_base_rate_steps = hold_base_rate_steps\n        self.name = name\n\n    def __call__(self, step):\n        return cosine_decay_with_warmup(\n            global_step=step,\n            learning_rate_base=self.learning_rate_base,\n            total_steps=self.total_steps,\n            warmup_learning_rate=self.warmup_learning_rate,\n            warmup_steps=self.warmup_steps,\n            hold_base_rate_steps=self.hold_base_rate_steps\n        )\n\n    def get_config(self):\n        return {\n            \"learning_rate_base\": self.learning_rate_base,\n            \"total_steps\": self.total_steps,\n            \"warmup_learning_rate\": self.warmup_learning_rate,\n            \"warmup_steps\": self.warmup_steps,\n            \"hold_base_rate_steps\": self.hold_base_rate_steps,\n            \"name\": self.name,\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.667690Z","iopub.execute_input":"2025-12-08T15:48:05.667873Z","iopub.status.idle":"2025-12-08T15:48:05.738679Z","shell.execute_reply.started":"2025-12-08T15:48:05.667859Z","shell.execute_reply":"2025-12-08T15:48:05.738138Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def save_plot(history, save_dir):\n\n    # Accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(save_dir + '_accuracy.jpg')\n    plt.close()\n\n    # Loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(['Train', 'Validation'], loc='upper left')\n    plt.savefig(save_dir + '_loss.jpg')\n    plt.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.739424Z","iopub.execute_input":"2025-12-08T15:48:05.739649Z","iopub.status.idle":"2025-12-08T15:48:05.744922Z","shell.execute_reply.started":"2025-12-08T15:48:05.739632Z","shell.execute_reply":"2025-12-08T15:48:05.744239Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def model_parameter():\n    param = {\n            \"backbone\": EfficientNetB5,\n            \"target\": 9,\n            \"resize\": 448,\n            \"metadata\": False,\n            \"initial_lr\": 3e-5,\n            \"epochs\": 15,\n            'input_image_size': 512,\n            'train_batch_size': 4,\n            'validation_batch_size': 4,\n            \"savedModelByName\": \"Model.keras\",\n            \"saveFinalModelBy\": \"Model\",\n            'log_by': \"Model.csv\",\n            'save_plot_name': 'Model',\n            'prediction_csv_name': 'Model_prediction',\n            'print_hyper_parameter': True,\n            'print_trainable_layers': False,\n            'print_model_summary': False,\n            'visualise_augmented_data': False\n            }\n    return param","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.745747Z","iopub.execute_input":"2025-12-08T15:48:05.745996Z","iopub.status.idle":"2025-12-08T15:48:05.759644Z","shell.execute_reply.started":"2025-12-08T15:48:05.745966Z","shell.execute_reply":"2025-12-08T15:48:05.758973Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialise the EfficientNet Model for transfer learning\ndef EffNet(input_size, num_classess, pretrained_model,\n           print_trainable_layers=False, print_model_summary=False):\n    # Get the EfficientNet Model\n    base_model = pretrained_model(\n        # weights='imagenet',\n        weights=\"/kaggle/input/efficientb5/efficientnetb5_notop.h5\",\n        input_shape=input_size,\n        include_top=False\n    )\n\n    # Keep the BatchNorm layer freeze, and unfreeze all other layers\n    def unfreeze_model(model, print_trainable, print_summary):\n        # unfreeze the layers while leaving BatchNorm layers frozen\n        for layer in model.layers[:]:\n            if isinstance(layer, layers.BatchNormalization):\n                layer.trainable = False\n                \n        # Print trainable layer summary\n        if print_trainable:\n            for layer in model.layers:\n                print(layer, layer.trainable)\n\n        # Print Model summary\n        if print_summary:\n            model.summary()\n\n    # Unfreeze the model\n    unfreeze_model(base_model, print_trainable_layers, print_model_summary)\n\n    # Add dense and output layer\n    model = keras.Sequential([\n    base_model,\n    layers.Flatten(name=\"top_flatten\"),\n    layers.Dense(500, activation=\"relu\", name=\"dense_500\"),\n    layers.Dense(256, activation=\"relu\", name=\"dense_256\"),\n    layers.Dense(num_classess, activation=\"softmax\", name=\"output_layer\"),\n    ])\n\n\n    # Initialise the optimizer and compile the model\n    lr_schedule = WarmUpCosineDecaySchedule(\n    learning_rate_base=hyper_param['learning_rate_base'],\n    total_steps=total_steps,\n    warmup_learning_rate=hyper_param['warmup_learning_rate'],\n    warmup_steps=warmup_steps,\n    hold_base_rate_steps=0,\n    )\n\n    optimizer = optimizers.Adam(learning_rate=lr_schedule)\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n\n    # print the FC layer summary\n    if print_model_summary:\n        model.summary()\n\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.760450Z","iopub.execute_input":"2025-12-08T15:48:05.760677Z","iopub.status.idle":"2025-12-08T15:48:05.777266Z","shell.execute_reply.started":"2025-12-08T15:48:05.760662Z","shell.execute_reply":"2025-12-08T15:48:05.776538Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Fit the model on training and validation dataset and star the training process.\ndef train_model(model, train_dataset, epoch,\n                validation_dataset, callback):\n\n    return model.fit(\n        train_dataset,\n        epochs=epoch,\n        validation_data=validation_dataset,\n        verbose=1,\n        callbacks=callback\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.778889Z","iopub.execute_input":"2025-12-08T15:48:05.779316Z","iopub.status.idle":"2025-12-08T15:48:05.795340Z","shell.execute_reply.started":"2025-12-08T15:48:05.779297Z","shell.execute_reply":"2025-12-08T15:48:05.794683Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Augment the dataset\nIMAGENET_MEAN = tf.constant([0.485, 0.456, 0.406], dtype=tf.float32)\nIMAGENET_STD  = tf.constant([0.229, 0.224, 0.225], dtype=tf.float32)\ndef augment(image, image_size, training=True):\n\n\n    image = tf.image.convert_image_dtype(image, tf.float32)\n\n    if training:\n\n        rand_scale = tf.random.uniform([], 0.8, 1.0)\n        orig_h = tf.shape(image)[0]\n        orig_w = tf.shape(image)[1]\n        crop_h = tf.cast(rand_scale * tf.cast(orig_h, tf.float32), tf.int32)\n        crop_w = tf.cast(rand_scale * tf.cast(orig_w, tf.float32), tf.int32)\n    \n        image = tf.image.random_crop(image, size=[crop_h, crop_w, 3])\n        image = tf.image.resize(image, [image_size, image_size])\n    \n        image = tf.image.random_flip_left_right(image)\n        image = tf.image.random_flip_up_down(image)\n    \n        k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n        image = tf.image.rot90(image, k=k)\n    \n        image = tf.image.random_brightness(image, max_delta=0.2)\n        image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n        image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n        image = tf.image.random_hue(image, max_delta=0.02)\n    \n        image = tf.clip_by_value(image, 0.0, 1.0)\n    \n        noise_std = tf.random.uniform([], 0.0, 0.05)  \n        noise = tf.random.normal(tf.shape(image), mean=0.0, stddev=noise_std)\n        image = image + noise\n        image = tf.clip_by_value(image, 0.0, 1.0)\n\n        def apply_cutout(img):\n            h = tf.shape(img)[0]\n            w = tf.shape(img)[1]\n        \n      \n            cutout_frac = tf.random.uniform([], 0.2, 0.4)\n            ch = tf.cast(cutout_frac * tf.cast(h, tf.float32), tf.int32)\n            cw = tf.cast(cutout_frac * tf.cast(w, tf.float32), tf.int32)\n        \n    \n            cy = tf.random.uniform([], 0, h - ch + 1, dtype=tf.int32)\n            cx = tf.random.uniform([], 0, w - cw + 1, dtype=tf.int32)\n        \n    \n            mask = tf.ones((h, w), dtype=tf.float32)\n            mask = tf.tensor_scatter_nd_update(\n                mask,\n                indices=tf.reshape(\n                    tf.stack(tf.meshgrid(tf.range(cy, cy + ch),\n                                         tf.range(cx, cx + cw),\n                                         indexing=\"ij\"), axis=-1),\n                    [-1, 2]\n                ),\n                updates=tf.zeros([ch * cw], dtype=tf.float32)\n            )\n        \n    \n            mask = tf.expand_dims(mask, -1)\n            mask = tf.concat([mask, mask, mask], axis=-1)\n        \n            return img * mask\n    \n        do_cutout = tf.less(tf.random.uniform([]), 0.5)\n        image = tf.cond(do_cutout, lambda: apply_cutout(image), lambda: image)\n\n    else:\n        image = tf.image.resize(image, [image_size, image_size])\n    \n    image = (image - IMAGENET_MEAN) / IMAGENET_STD\n    \n    return image\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:05.796190Z","iopub.execute_input":"2025-12-08T15:48:05.796399Z","iopub.status.idle":"2025-12-08T15:48:06.408767Z","shell.execute_reply.started":"2025-12-08T15:48:05.796384Z","shell.execute_reply":"2025-12-08T15:48:06.407991Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1765208886.378971      94 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ndef build_tf_dataset(\n    df,\n    image_size,\n    batch_size,\n    num_classes,\n    label_col=\"diagnosis_idx\",\n    shuffle=False,\n    repeat=False,\n    training=True,\n):\n    paths = df[\"image\"].values\n    labels = df[label_col].values.astype(\"int32\")\n\n    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n\n    if shuffle:\n        ds = ds.shuffle(len(df), reshuffle_each_iteration=True)\n\n    def _load_image(path, label):\n        image_bytes = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image_bytes, channels=3)\n        image = augment(image, image_size, training=training)\n        label_onehot = tf.one_hot(label, num_classes)\n        return image, label_onehot\n\n    ds = ds.map(_load_image, num_parallel_calls=AUTOTUNE)\n\n    if repeat:\n        ds = ds.repeat()\n\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:06.409642Z","iopub.execute_input":"2025-12-08T15:48:06.409825Z","iopub.status.idle":"2025-12-08T15:48:06.423702Z","shell.execute_reply.started":"2025-12-08T15:48:06.409810Z","shell.execute_reply":"2025-12-08T15:48:06.423053Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def build_tf_test_dataset(df, image_size, batch_size):\n    paths = df[\"image\"].values\n    ds = tf.data.Dataset.from_tensor_slices(paths)\n\n    def _load_image(path):\n        image_bytes = tf.io.read_file(path)\n        image = tf.image.decode_jpeg(image_bytes, channels=3)\n        image = augment(image, image_size, training=False)  \n        return image\n\n    ds = ds.map(_load_image, num_parallel_calls=AUTOTUNE)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(AUTOTUNE)\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:06.424400Z","iopub.execute_input":"2025-12-08T15:48:06.424624Z","iopub.status.idle":"2025-12-08T15:48:06.437850Z","shell.execute_reply.started":"2025-12-08T15:48:06.424607Z","shell.execute_reply":"2025-12-08T15:48:06.437141Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # Data path\n    TRAIN_CSV = \"/kaggle/input/processedcsvs/Processed CSV's/train_2020_and_2019_with_9_Labels.csv\"\n    TEST_CSV  = \"/kaggle/input/processedcsvs/Processed CSV's/test_2020_no_PateintDetail.csv\"\n    TRAIN_IMG_DIR_1 = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/train\"\n    TRAIN_IMG_DIR_2 = \"/kaggle/input/isic-2019/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n    TEST_IMG_DIR = \"/kaggle/input/siim-isic-melanoma-classification/jpeg/test\"\n\n    #  load model parameter\n    selected_model = model_parameter()\n\n    # Define log, plot, model, prediction files\n    log_path = \"./runs/\"\n    os.makedirs(log_path, exist_ok=True)\n\n    plot_path = \"./plot/\"\n    os.makedirs(plot_path, exist_ok=True)\n\n    save_model_path = \"./saveModel/\"\n    os.makedirs(save_model_path, exist_ok=True)\n\n    prediction_path = \"./prediction/\"\n    os.makedirs(prediction_path, exist_ok=True)\n\n    # join CSV & image path\n    label = pd.read_csv(TRAIN_CSV)\n    class_names = sorted(label[\"diagnosis\"].unique())\n    label2idx = {c: i for i, c in enumerate(class_names)}\n    idx2label = {i: c for c, i in label2idx.items()}\n\n    label[\"diagnosis_idx\"] = label[\"diagnosis\"].map(label2idx)\n    num_classes = len(class_names)\n    test_csv = pd.read_csv(TEST_CSV)\n\n    def attach_train_paths(df):\n        df = df.copy()\n        df[\"image\"] = df[\"image\"].astype(str) + \".jpg\"\n\n        full_paths = []\n        miss_cnt = 0\n\n        for img in df[\"image\"]:\n            p1 = os.path.join(TRAIN_IMG_DIR_1, img)  # 2020\n            p2 = os.path.join(TRAIN_IMG_DIR_2, img)  # 2019\n\n            if os.path.exists(p1):\n                full_paths.append(p1)\n            elif os.path.exists(p2):\n                full_paths.append(p2)\n            else:\n                full_paths.append(p1)\n                miss_cnt += 1\n\n        if miss_cnt > 0:\n            print(f\"[WARNING] {miss_cnt} images not found in either train dir, \"\n                  f\"using 2020 path by default. Check names or dirs.\")\n            \n        df[\"image\"] = full_paths\n        return df\n\n    label = attach_train_paths(label)\n\n    def attach_test_paths(df):\n        df = df.copy()\n        df[\"image\"] = df[\"image\"].astype(str) + \".jpg\"\n        df[\"image\"] = df[\"image\"].apply(\n            lambda x: os.path.join(TEST_IMG_DIR, x)\n        )\n        return df\n    test_csv = attach_test_paths(test_csv)\n\n    # Hyper Parameter\n    hyper_param = {\n        'seed': 42,\n        'image_size': selected_model['resize'],\n        'backbone_model': selected_model['backbone'],\n        'early_stop': 10,\n        'num_class': selected_model['target'],\n        'train_batch_size': selected_model['train_batch_size'],\n        'test_batch_size': 1,\n        'validation_batch_size': selected_model['validation_batch_size'],\n        'epoch': selected_model['epochs'],\n        'warmup_epoch': 1,\n        'learning_rate_base': selected_model['initial_lr'],\n        'warmup_learning_rate': selected_model['initial_lr'],\n        'training_sample_count': label.shape[0],\n        'save_model': selected_model['savedModelByName'],\n        'save_final_model': selected_model['saveFinalModelBy']\n    }\n\n    image_resize = (hyper_param['image_size'], hyper_param['image_size'])\n    image_shape = image_resize + (3,)\n\n    # Total training steps in Warmup\n    total_steps = int(hyper_param['epoch'] *\n                      hyper_param['training_sample_count'] /\n                      hyper_param['train_batch_size'])\n    # Compute the number of warmup batches.\n    warmup_steps = int(hyper_param['warmup_epoch'] *\n                       hyper_param['training_sample_count'] /\n                       hyper_param['train_batch_size'])\n\n    # Print Hyper parameter\n    if selected_model['print_hyper_parameter']:\n        print(\"\\n####################### Hyper Parameter #################################\\n\")\n        pprint.pprint(hyper_param)\n        print('\\nImage Shape: {}'.format(image_shape))\n        print('Total training steps in Warmup: {}'.format(total_steps))\n        print('Number of Warmup Batch: {}\\n'.format(warmup_steps))\n        print(\"\\nTrain Label shape: \", label.shape)\n        print(\"Test Label shape: \", test_csv.shape)\n\n\n    #Initialise Pre-train Model\n    # model = EffNet(\n    #     input_size=image_shape,\n    #     num_classess=hyper_param['num_class'],\n    #     pretrained_model=hyper_param['backbone_model'],\n    #     print_trainable_layers=selected_model['print_trainable_layers'],\n    #     print_model_summary=selected_model['print_model_summary']\n    # )\n    model = tf.keras.models.load_model(\"/kaggle/input/saved/keras/default/1/Model.keras\",compile=False)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=hyper_param['learning_rate_base'])\n    model.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n\n    # Preprocess and Augment Image for train, test and validation set. \n    image_size = hyper_param['image_size']\n    train_bs = hyper_param['train_batch_size']\n    val_bs = hyper_param['validation_batch_size']\n    train_df, val_df = train_test_split(label,test_size=0.2,random_state=hyper_param['seed'],stratify=label['diagnosis'])\n\n\n    # Prepare train, validation Generator\n    train_ds = build_tf_dataset(\n        df=train_df,\n        image_size=image_size,\n        batch_size=train_bs,\n        num_classes=hyper_param['num_class'],\n        label_col=\"diagnosis_idx\",\n        shuffle=True,\n        repeat=False,\n        training=True,      \n    )\n    \n    val_ds = build_tf_dataset(\n        df=val_df,\n        image_size=image_size,\n        batch_size=val_bs,\n        num_classes=hyper_param['num_class'],\n        label_col=\"diagnosis_idx\",\n        shuffle=False,\n        repeat=False,\n        training=False,    \n    )\n    # Define Early Stopping on validation loss\n    es = callbacks.EarlyStopping(\n        monitor='val_loss',\n        mode='min',\n        patience=hyper_param['early_stop'],\n        verbose=1,\n        restore_best_weights=True\n    )\n\n    # Save model after each epoch\n    ck = callbacks.ModelCheckpoint(\n        filepath=os.path.join(save_model_path, hyper_param['save_model']),\n        monitor='val_loss',\n        verbose=1,\n        save_best_only=False,\n        save_weights_only=False,\n    )\n\n    # Save logs to CSV\n    logs = callbacks.CSVLogger(\n        os.path.join(log_path, selected_model['log_by']),\n        separator=\",\",\n        append=False\n    )\n\n    # Callback list\n    call_backs = [ck, logs, es]\n\n    already_trained= 12\n\n    # Start the training process\n    print('\\n\\n---------------- Staring the Training Process... --------------- ')\n    history = model.fit(\n        train_ds,\n        epochs=hyper_param['epoch'],\n        initial_epoch=already_trained,\n        validation_data=val_ds,\n        callbacks=call_backs,\n        verbose=1\n    )\n    print(\"\\n ----------------- Model is trained --------------------------\")\n\n    # Training and validation: accuracy & loss\n    print(\"\\n------ Saving Training and Validation Plot --------\")\n    save_plot(history=history,\n              save_dir=os.path.join(plot_path, selected_model['save_plot_name']))\n\n    # Predict on Testing Set\n    test_ds = build_tf_test_dataset(\n        df=test_csv,\n        image_size=image_size,\n        batch_size=hyper_param['test_batch_size'],         \n    )\n\n    print(\"\\n------ Predicting on Testset --------\")\n    pred = model.predict(test_ds, verbose=1)\n    predicted_class_indices = np.argmax(pred, axis=1)\n\n    # Map the predicted labels with their unique ids\n    predictions = [idx2label[i] for i in predicted_class_indices]\n\n    results = pd.DataFrame({\n        \"Filename\": test_csv[\"image\"],   \n        \"Predictions\": predictions\n    })\n\n    results.to_csv(\n        os.path.join(prediction_path, selected_model['prediction_csv_name'] + \".csv\"),\n        index=False\n    )\n\n    # Save Trained Model\n    print(\"\\n ------------ Saving the Trained model ------------------------------------\")\n    final_model_dir = os.path.join(save_model_path, hyper_param['save_final_model'])\n    os.makedirs(final_model_dir, exist_ok=True)\n\n    model.save(final_model_dir + \".keras\", include_optimizer=True)\n\n    print(\"\\n---------------------- Completed Model Training & Prediction ---------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T15:48:06.438728Z","iopub.execute_input":"2025-12-08T15:48:06.439245Z","iopub.status.idle":"2025-12-08T19:57:20.647079Z","shell.execute_reply.started":"2025-12-08T15:48:06.439221Z","shell.execute_reply":"2025-12-08T19:57:20.645300Z"}},"outputs":[{"name":"stdout","text":"\n####################### Hyper Parameter #################################\n\n{'backbone_model': <function EfficientNetB5 at 0x7a79bd45cae0>,\n 'early_stop': 10,\n 'epoch': 15,\n 'image_size': 448,\n 'learning_rate_base': 3e-05,\n 'num_class': 9,\n 'save_final_model': 'Model',\n 'save_model': 'Model.keras',\n 'seed': 42,\n 'test_batch_size': 1,\n 'train_batch_size': 4,\n 'training_sample_count': 58031,\n 'validation_batch_size': 4,\n 'warmup_epoch': 1,\n 'warmup_learning_rate': 3e-05}\n\nImage Shape: (448, 448, 3)\nTotal training steps in Warmup: 217616\nNumber of Warmup Batch: 14507\n\n\nTrain Label shape:  (58031, 3)\nTest Label shape:  (10875, 1)\n\n\n---------------- Staring the Training Process... --------------- \nEpoch 13/15\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1765209288.576051     144 service.cc:148] XLA service 0x7a7914002130 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1765209288.577087     144 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1765209298.736842     144 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1765209358.481746     144 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.8426 - loss: 0.4664\nEpoch 13: saving model to ./saveModel/Model.keras\n\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4658s\u001b[0m 390ms/step - accuracy: 0.8426 - loss: 0.4664 - val_accuracy: 0.8464 - val_loss: 0.4448\nEpoch 14/15\n\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.8484 - loss: 0.4400\nEpoch 14: saving model to ./saveModel/Model.keras\n\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4530s\u001b[0m 390ms/step - accuracy: 0.8484 - loss: 0.4400 - val_accuracy: 0.8576 - val_loss: 0.4209\nEpoch 15/15\n\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.8545 - loss: 0.4233\nEpoch 15: saving model to ./saveModel/Model.keras\n\u001b[1m11606/11606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4565s\u001b[0m 393ms/step - accuracy: 0.8545 - loss: 0.4233 - val_accuracy: 0.8597 - val_loss: 0.4217\nRestoring model weights from the end of the best epoch: 14.\n\n ----------------- Model is trained --------------------------\n\n------ Saving Training and Validation Plot --------\n\n------ Predicting on Testset --------\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1765222997.494456     146 buffer_comparator.cc:157] Difference at 6: 1808, expected 2009\nE0000 00:00:1765222997.495530     146 buffer_comparator.cc:157] Difference at 9: 1826, expected 2033\nE0000 00:00:1765222997.495544     146 buffer_comparator.cc:157] Difference at 13: 1822, expected 2027\nE0000 00:00:1765222997.495548     146 buffer_comparator.cc:157] Difference at 14: 1817, expected 2023\nE0000 00:00:1765222997.495551     146 buffer_comparator.cc:157] Difference at 20: 1817, expected 2024\nE0000 00:00:1765222997.495555     146 buffer_comparator.cc:157] Difference at 23: 1825, expected 2028\nE0000 00:00:1765222997.495558     146 buffer_comparator.cc:157] Difference at 24: 1820, expected 2024\nE0000 00:00:1765222997.495562     146 buffer_comparator.cc:157] Difference at 29: 1826, expected 2030\nE0000 00:00:1765222997.495565     146 buffer_comparator.cc:157] Difference at 30: 1813, expected 2015\nE0000 00:00:1765222997.495569     146 buffer_comparator.cc:157] Difference at 34: 1814, expected 2021\n2025-12-08 19:43:17.495583: E external/local_xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:348] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\nE0000 00:00:1765222997.507661     146 buffer_comparator.cc:157] Difference at 6: 1808, expected 2009\nE0000 00:00:1765222997.507703     146 buffer_comparator.cc:157] Difference at 9: 1826, expected 2033\nE0000 00:00:1765222997.507707     146 buffer_comparator.cc:157] Difference at 13: 1822, expected 2027\nE0000 00:00:1765222997.507711     146 buffer_comparator.cc:157] Difference at 14: 1817, expected 2023\nE0000 00:00:1765222997.507715     146 buffer_comparator.cc:157] Difference at 20: 1817, expected 2024\nE0000 00:00:1765222997.507718     146 buffer_comparator.cc:157] Difference at 23: 1825, expected 2028\nE0000 00:00:1765222997.507722     146 buffer_comparator.cc:157] Difference at 24: 1820, expected 2024\nE0000 00:00:1765222997.507726     146 buffer_comparator.cc:157] Difference at 29: 1826, expected 2030\nE0000 00:00:1765222997.507729     146 buffer_comparator.cc:157] Difference at 30: 1813, expected 2015\nE0000 00:00:1765222997.507732     146 buffer_comparator.cc:157] Difference at 34: 1814, expected 2021\n2025-12-08 19:43:17.507745: E external/local_xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:348] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\nE0000 00:00:1765222997.521779     146 buffer_comparator.cc:157] Difference at 6: 1808, expected 2009\nE0000 00:00:1765222997.521817     146 buffer_comparator.cc:157] Difference at 9: 1826, expected 2033\nE0000 00:00:1765222997.521822     146 buffer_comparator.cc:157] Difference at 13: 1822, expected 2027\nE0000 00:00:1765222997.521826     146 buffer_comparator.cc:157] Difference at 14: 1817, expected 2023\nE0000 00:00:1765222997.521830     146 buffer_comparator.cc:157] Difference at 20: 1817, expected 2024\nE0000 00:00:1765222997.521833     146 buffer_comparator.cc:157] Difference at 23: 1825, expected 2028\nE0000 00:00:1765222997.521837     146 buffer_comparator.cc:157] Difference at 24: 1820, expected 2024\nE0000 00:00:1765222997.521840     146 buffer_comparator.cc:157] Difference at 29: 1826, expected 2030\nE0000 00:00:1765222997.521844     146 buffer_comparator.cc:157] Difference at 30: 1813, expected 2015\nE0000 00:00:1765222997.521847     146 buffer_comparator.cc:157] Difference at 34: 1814, expected 2021\n2025-12-08 19:43:17.521858: E external/local_xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:348] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\nE0000 00:00:1765222997.534380     146 buffer_comparator.cc:157] Difference at 6: 1808, expected 2009\nE0000 00:00:1765222997.534421     146 buffer_comparator.cc:157] Difference at 9: 1826, expected 2033\nE0000 00:00:1765222997.534425     146 buffer_comparator.cc:157] Difference at 13: 1822, expected 2027\nE0000 00:00:1765222997.534429     146 buffer_comparator.cc:157] Difference at 14: 1817, expected 2023\nE0000 00:00:1765222997.534433     146 buffer_comparator.cc:157] Difference at 20: 1817, expected 2024\nE0000 00:00:1765222997.534436     146 buffer_comparator.cc:157] Difference at 23: 1825, expected 2028\nE0000 00:00:1765222997.534441     146 buffer_comparator.cc:157] Difference at 24: 1820, expected 2024\nE0000 00:00:1765222997.534444     146 buffer_comparator.cc:157] Difference at 29: 1826, expected 2030\nE0000 00:00:1765222997.534448     146 buffer_comparator.cc:157] Difference at 30: 1813, expected 2015\nE0000 00:00:1765222997.534451     146 buffer_comparator.cc:157] Difference at 34: 1814, expected 2021\n2025-12-08 19:43:17.534462: E external/local_xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:348] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\nE0000 00:00:1765222997.549662     146 buffer_comparator.cc:157] Difference at 6: 1808, expected 2009\nE0000 00:00:1765222997.549711     146 buffer_comparator.cc:157] Difference at 9: 1826, expected 2033\nE0000 00:00:1765222997.549716     146 buffer_comparator.cc:157] Difference at 13: 1822, expected 2027\nE0000 00:00:1765222997.549719     146 buffer_comparator.cc:157] Difference at 14: 1817, expected 2023\nE0000 00:00:1765222997.549723     146 buffer_comparator.cc:157] Difference at 20: 1817, expected 2024\nE0000 00:00:1765222997.549727     146 buffer_comparator.cc:157] Difference at 23: 1825, expected 2028\nE0000 00:00:1765222997.549730     146 buffer_comparator.cc:157] Difference at 24: 1820, expected 2024\nE0000 00:00:1765222997.549734     146 buffer_comparator.cc:157] Difference at 29: 1826, expected 2030\nE0000 00:00:1765222997.549737     146 buffer_comparator.cc:157] Difference at 30: 1813, expected 2015\nE0000 00:00:1765222997.549741     146 buffer_comparator.cc:157] Difference at 34: 1814, expected 2021\n2025-12-08 19:43:17.549752: E external/local_xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:348] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m10875/10875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m825s\u001b[0m 74ms/step\n\n ------------ Saving the Trained model ------------------------------------\n\n---------------------- Completed Model Training & Prediction ---------------------------\n","output_type":"stream"}],"execution_count":14}]}